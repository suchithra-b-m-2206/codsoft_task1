# -*- coding: utf-8 -*-
"""task 1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mbTqNBIK42ekK4G_s8g0wwtYChHetTil
"""

!pip install pycaret

! pip install tpot

!pip install catboost

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, VotingClassifier, AdaBoostClassifier, BaggingClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
import xgboost as xgb
from catboost import CatBoostClassifier
from lightgbm import LGBMClassifier
from tpot import TPOTClassifier
from lazypredict.Supervised import LazyClassifier

from sklearn.metrics import confusion_matrix , classification_report ,accuracy_score

!pip install lazypredict

titanic=pd.read_csv("/content/sample_data/Titanic-Dataset.csv")
titanic.head()

titanic.info()

titanic.describe(include='all')

titanic.isna().sum()

titanic.duplicated().sum()

sex_counts=titanic['Sex'].value_counts()
sex_counts

plt.figure(figsize=(12,8))
sns.barplot(x=sex_counts.index,y=sex_counts.values,palette='viridis')
plt.title('sex_counts')
plt.xlabel('gender')
plt.ylabel('count')
plt.show()

#the most 5 age in data
age_counts=titanic['Age'].value_counts().head()

plt.figure(figsize=(12,8))
sns.barplot(x=age_counts.index,y=age_counts.values,palette='viridis')
plt.title('age_counts')
plt.xlabel('Age')
plt.ylabel('count')
plt.show()
age_counts

pclass_counts=titanic['Pclass'].value_counts()
pclass_counts

plt.figure(figsize = (20, 6))
explode = (0,0,0.05)
pclass_counts.plot(kind = 'pie', fontsize = 12, explode = explode, autopct = '%.1f%%')
plt.title('pclass')
plt.xlabel('pclass', weight = "bold", color = "#000000", fontsize = 14, labelpad = 20)
plt.ylabel('counts', weight = "bold", color = "#000000", fontsize = 14, labelpad = 20)
plt.legend(labels = pclass_counts.index, loc = "best")
plt.show()

SibSp_counts=titanic['SibSp'].value_counts()
SibSp_counts

plt.figure(figsize=(12,8))
sns.barplot(x=SibSp_counts.index,y=SibSp_counts.values,palette='viridis')
plt.title('sibsp_counts')
plt.xlabel('sibsp')
plt.ylabel('count')
plt.show()

Parch_counts=titanic['Parch'].value_counts()
Parch_counts

plt.figure(figsize=(12,8))
sns.barplot(x=Parch_counts.index,y=Parch_counts.values,palette='viridis')
plt.title('Parch_counts')
plt.xlabel('Parch')
plt.ylabel('count')
plt.show()

Embarked_counts=titanic['Embarked'].value_counts()
Embarked_counts

plt.figure(figsize = (20, 6))
explode = (0,0,0.05)
Embarked_counts.plot(kind = 'pie', fontsize = 12, explode = explode, autopct = '%.1f%%')
plt.title('Embarked')
plt.xlabel('Embarked', weight = "bold", color = "#000000", fontsize = 14, labelpad = 20)
plt.ylabel('counts', weight = "bold", color = "#000000", fontsize = 14, labelpad = 20)
plt.legend(labels = Embarked_counts.index, loc = "best")
plt.show()

Survived_counts=titanic['Survived'].value_counts()
Survived_counts

plt.figure(figsize = (20, 6))
explode = (0,0.05)
Survived_counts.plot(kind = 'pie', fontsize = 12, explode = explode, autopct = '%.1f%%')
plt.title('Survived')
plt.xlabel('Survived', weight = "bold", color = "#000000", fontsize = 14, labelpad = 20)
plt.ylabel('counts', weight = "bold", color = "#000000", fontsize = 14, labelpad = 20)
plt.legend(labels = Survived_counts.index, loc = "best")
plt.show()

age=sns.FacetGrid(titanic,col='Survived')
age.map(plt.hist,'Age',bins=20)

gender=sns.FacetGrid(titanic,col='Survived')

gender.map(plt.hist,'Sex',bins=2)

sibsp=sns.FacetGrid(titanic,col='Survived')
plt.xticks(SibSp_counts.index)
sibsp.map(plt.hist,'SibSp',bins=9)

pclass=sns.FacetGrid(titanic,col='Survived')
plt.xticks([1,2,3])
pclass.map(plt.hist,'Pclass')

pclass=sns.FacetGrid(titanic,col='Survived')
plt.xticks(Parch_counts.index)
pclass.map(plt.hist,'Parch')

titanic=titanic.drop(columns=['PassengerId', 'Name', 'Cabin', 'Ticket'], axis=1)
titanic.head()

### convert the gender to binary 0 and 1
titanic['Sex']=titanic['Sex'].replace({'male':1,'female':0})
titanic.head()

# Fill missing values in age column by imputing the median
titanic['Age'].fillna(titanic['Age'].median(), inplace=True)
titanic.isna().sum()

# Fill missing values in embarked column by imputing the mode
titanic["Embarked"].fillna(titanic["Embarked"].mode()[0], inplace=True)
titanic.isna().sum()

titanic['Embarked']=titanic['Embarked'].replace({'S':1,'C':2,'Q':3})
titanic.head()

titanic.corr()

plt.figure(figsize=(16, 10))
sns.heatmap(titanic.corr(), annot=True)
plt.show()

x=titanic.drop(columns=['Survived'])
y=titanic['Survived']

scaler=MinMaxScaler()
x=scaler.fit_transform(x)

y=y.values.reshape(-1,1)

X_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.2,shuffle=True,random_state=42)

lg=LogisticRegression(penalty="l2",max_iter=1000,solver="lbfgs")
lg.fit(X_train,y_train)

lg.score(X_train,y_train)

y_pred=lg.predict(X_test)

print(accuracy_score(y_test,y_pred))

from sklearn.metrics import ConfusionMatrixDisplay
ConfusionMatrixDisplay.from_predictions(y_test, y_pred)
print(confusion_matrix(y_test, y_pred))

print(classification_report(y_test, y_pred))

Dt=DecisionTreeClassifier()
Dt.fit(X_train,y_train)

Dt.score(X_train,y_train)

y_pred=Dt.predict(X_test)

print(accuracy_score(y_test,y_pred))

from sklearn.metrics import ConfusionMatrixDisplay
ConfusionMatrixDisplay.from_predictions(y_test, y_pred)
print(confusion_matrix(y_test, y_pred))

print(classification_report(y_test, y_pred))

Rf=RandomForestClassifier(n_estimators=1000)
Rf.fit(X_train,y_train)

Rf.score(X_train,y_train)

y_pred=Rf.predict(X_test)

y_pred=Rf.predict(X_test)

from sklearn.metrics import ConfusionMatrixDisplay
ConfusionMatrixDisplay.from_predictions(y_test, y_pred)
print(confusion_matrix(y_test, y_pred))

print(classification_report(y_test, y_pred))

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(5)
knn.fit(X_train,y_train)

knn.score(X_train,y_train)

pred=knn.predict(X_test)

print(accuracy_score(y_test,y_pred))

from sklearn.metrics import ConfusionMatrixDisplay
ConfusionMatrixDisplay.from_predictions(y_test, y_pred,cmap="magma")
print(confusion_matrix(y_test, y_pred))

svm = SVC(kernel="rbf", C=1.0)
svm.fit(X_train, y_train)

svm.score(X_train, y_train)

y_pre=svm.predict(X_test)

y_pre=svm.predict(X_test)

from sklearn.metrics import ConfusionMatrixDisplay
ConfusionMatrixDisplay.from_predictions(y_test, y_pre,cmap="magma")
print(confusion_matrix(y_test, y_pre))

gnb = GaussianNB()
gnb.fit(X_train, y_train)

svm.score(X_train, y_train)

svm.score(X_train, y_train)

print(accuracy_score(y_test,y_pre))

from sklearn.metrics import ConfusionMatrixDisplay
ConfusionMatrixDisplay.from_predictions(y_test, y_pre,cmap="magma")
print(confusion_matrix(y_test, y_pre))

xg=xgb.XGBClassifier(objective="binary:logistic",random_state=42,n_estimators=1000, learning_rate=0.001, max_depth=7)
xg.fit(X_train, y_train,early_stopping_rounds=100, eval_set=[(X_test, y_test)])

xg.score(X_train, y_train)

ypred=xg.predict(X_test)

"""# New Section"""

print(accuracy_score(y_test,ypred))

from sklearn.metrics import ConfusionMatrixDisplay
ConfusionMatrixDisplay.from_predictions(y_test, ypred,cmap="magma")
print(confusion_matrix(y_test, ypred))

catboost_clf = CatBoostClassifier(iterations=5000, depth=5, learning_rate=0.001, random_state=0)
catboost_clf.fit(X_train, y_train)